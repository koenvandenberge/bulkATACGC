---
title: "Calderon simulation analysis"
author: "Koen Van den Berge"
date: "7/21/2020"
output: html_document
---

```{r}
library(GenomicAlignments)
library(tidyverse)
library(cqn)
library(RColorBrewer)
library(edgeR)
library(ggplot2)
library(cowplot)
library(ggridges)
library(gridExtra)
library(iCOBRA)
library(qsmooth)
gcqn_qsmooth <- function(counts, gcGroups, bio){
  gcBinNormCounts <- matrix(NA, nrow=nrow(counts), ncol=ncol(counts), dimnames=list(rownames(counts),colnames(counts)))
  for(ii in 1:nlevels(gcGroups)){
    id <- which(gcGroups==levels(gcGroups)[ii])
    countBin <- counts[id,]
    qs <- qsmooth(countBin, group_factor=bio)
    normCountBin <- qs@qsmoothData
    normCountBin <- round(normCountBin)
    normCountBin[normCountBin<0] <- 0
    gcBinNormCounts[id,] <- normCountBin
  }
  return(gcBinNormCounts)
}
colsBig <- clusterExperiment:::massivePalette
plotGCHex <- function(gr, counts){
  counts2 <- counts
  df <- as_tibble(cbind(counts2,gc=mcols(gr)$gc))
  df <- gather(df, sample, value, -gc)
  ggplot(data=df, aes(x=gc, y=log(value+1)) ) + 
    ylab("log(count + 1)") + xlab("GC-content") + 
    geom_hex(bins = 50) + theme_bw() #+ facet_wrap(~sample, nrow=2)
}
pal <- RColorBrewer::brewer.pal(n=8, "Dark2")
source("../../../methods/gcqn_validated.R")

### this dataset combines samples from a number of different sources, therefore the GC effects are wildly different between samples.
data=read.delim("../../../data/calderon2019_GSE118189/GSE118189_ATAC_counts.txt.gz")
colnames(data) <- substr(colnames(data),2,nchar(colnames(data)))

# get GC content
rn <- rownames(data)
sn <- unlist(lapply(lapply(strsplit(rn,split="_"),"[",1),function(x) gsub(pattern="chr",x=x,replacement="")))
start <- as.numeric(unlist(lapply(strsplit(rn,split="_"),"[",2)))
end <- as.numeric(unlist(lapply(strsplit(rn,split="_"),"[",3)))
gr <- GRanges(seqnames=sn, ranges=IRanges(start, end), strand="*", mcols=data.frame(peakID=rn))
ff <- FaFile("~/data/genomes/human/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa")
peakSeqs <- getSeq(x=ff, gr)
gcContentPeaks <- letterFrequency(peakSeqs, "GC",as.prob=TRUE)[,1]
gcGroups <- Hmisc::cut2(gcContentPeaks, g=20)
mcols(gr)$gc <- gcContentPeaks

# get metadata
cnames <- colnames(data)
donor <- unlist(lapply(strsplit(cnames,split=".",fixed=TRUE),"[",1))
celltype <- factor(unlist(lapply(strsplit(cnames,split=".",fixed=TRUE),"[",2)))
condition <- unlist(lapply(strsplit(cnames,split=".",fixed=TRUE),"[",3))
table(celltype,condition)

# QC measures
qcMeasures <- openxlsx::read.xlsx(xlsxFile = "../../../data/calderon2019_GSE118189/Supplementary_tables.xlsx",
                    sheet = 5)
qcMeasures <- qcMeasures[,1:4]
qcMeasures$sample <- gsub(x=qcMeasures$sample, pattern="-", replacement=".", fixed=TRUE)
rownames(qcMeasures) <- qcMeasures$sample
qcMeasures <- qcMeasures[colnames(data),]

# batch
addSamples <- read.table("../../../data/calderon2019_GSE118189/samples_with_additional_resequencing.txt",
                         stringsAsFactors = FALSE)[,1]
addSamples <- gsub(x=addSamples, pattern="-", replacement=".", fixed=TRUE)
batch2 <- rep(0, ncol(data))
names(batch2) <- colnames(data)
batch2[addSamples]<- 1
batch2 <- factor(batch2)
batch <- droplevels(interaction(donor, batch2))

table(celltype,condition, batch)
counts <- as.matrix(data) ; rm(data, qcMeasures) ; gc()
```


```{r}
# keep <- rowSums(cpm(counts) > 2) >= 8
tCellId <- grep(x=celltype, pattern="_T")
countsT <- counts[, tCellId]
cellT <- droplevels(celltype[tCellId])
batchT <- droplevels(batch[tCellId])
conditionT <- factor(condition[tCellId])
# remove batches with only a few samples
rmBatch <- which(batchT %in% c("1003.0", "1008.0", "1010.0", "1011.0", "1001.1"))
cellT <- droplevels(cellT[-rmBatch])
batchT <- droplevels(batchT[-rmBatch])
conditionT <- droplevels(conditionT[-rmBatch])
countsT <- counts[, -rmBatch]

## focus on unstimulated condition
unStimCells <- which(conditionT == "U")
cellT <- droplevels(cellT[unStimCells])
batchT <- droplevels(batchT[unStimCells])
countsT <- counts[,unStimCells]
table(cellT, batchT)

set.seed(15)
grp <- rep(NA, length(cellT))
grpVals <- c("A", "B")
for(cc in 1:nlevels(cellT)){
  id <- which(cellT == levels(cellT)[cc])
  if(length(id) > 1){
    halfLength <- length(id)/2
    g1 <- sample(grpVals, 1)
    if(halfLength%%1 == 0){
      grp[id[1:halfLength]] <- g1
      grp[id[(halfLength+1):length(id)]] <- grpVals[!grpVals %in% g1]
    } else {
      grp[id[1:floor(halfLength)]] <- g1
      grp[id[ceiling(halfLength):length(id)]] <- grpVals[!grpVals %in% g1]
    }
  }
}
table(cellT, grp)

rmNA <- which(is.na(grp))
countsT <- countsT[,-rmNA]
grp <- grp[-rmNA]


keep <- rowSums(cpm(countsT) > 2) >= 8
countsTFilt <- countsT[keep,]
gcFilt <- gcContentPeaks[keep]
widthFilt <- width(gr)[keep]

rm(counts) ; gc()
```

# Mock comparison

```{r}
testEdgeR <- function(counts, design, tmm=FALSE, offset=NULL){
  d <- DGEList(counts)
  if(tmm) d <- calcNormFactors(d)
  if(!is.null(offset)) d$offset <- offset
  d <- estimateDisp(d, design)
  fit <- glmFit(d, design)
  lrt <- glmLRT(fit, coef=2)
  lrt$table$padj <- p.adjust(lrt$table$PValue, "fdr")
  return(lrt)
}
design <-  model.matrix(~factor(grp))


## TMM
d <- DGEList(countsTFilt)
d <- calcNormFactors(d)
cpmTMM <- edgeR::cpm(d, normalized.lib.sizes=TRUE, log=TRUE, prior.count=0.25)

## FQN
fqcountsTFilt <- FQnorm(countsTFilt)
cpmFQ <- edgeR::cpm(fqcountsTFilt, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)

## cqn
cqnObj <- cqn(countsTFilt, x=gcFilt, lengths=widthFilt, sizeFactors=colSums(countsTFilt))
cqnplot(cqnObj, xlab="GC content", lwd=2)
cqncountsTFilt <- 2^(cqnObj$y + cqnObj$offset)
cpmCqn <- edgeR::cpm(cqncountsTFilt, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)

## RUVg
library(RUVSeq)
hk <- readRDS("~/data/genomes/hkListHumanGenomicRanges.rds")
qh <- queryHits(findOverlaps(gr[keep], hk, type="within"))
negcon <- rownames(countsTFilt)[qh]
ruvRes <- RUVg(as.matrix(countsTFilt), negcon, k=2)
ruvgcountsTFilt <- ruvRes$normalizedCounts
cpmRUV <- edgeR::cpm(ruvgcountsTFilt, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)

## RUVs
scid <- matrix(c(which(grp == "A"),
         which(grp == "B")),
       nrow=2, ncol=21, byrow=TRUE)
ruvsRes <- RUVs(as.matrix(countsTFilt), 
                cIdx = 1:nrow(countsTFilt),
                scIdx = scid,
                k=2)
ruvscountsTFilt <- ruvsRes$normalizedCounts


## GCQN:
gcGroups <- Hmisc::cut2(gcFilt, g=20)
countsTFiltGCQN <- gcqn(countsTFilt, gcGroups, summary="median", round=TRUE)
cpmGCQN <- edgeR::cpm(countsTFiltGCQN, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)

## EDASeq
library(EDASeq)
wit <- withinLaneNormalization(x=as.matrix(countsTFilt), y=gcFilt, which="full")
countsTFiltEDASeq <- betweenLaneNormalization(wit, "full")
cpmEDASeq <- edgeR::cpm(countsTFiltEDASeq, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)

# PCA plots on CPM
rafalib::mypar(mfrow=c(3,2))
plotMDS(cpmTMM, main="TMM", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
plotMDS(cpmCqn, main="cqn", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
plotMDS(cpmFQ, main="full quantile", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
plotMDS(cpmGCQN, main="GCQN", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
plotMDS(cpmEDASeq, main="EDASeq", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
plotMDS(cpmRUV, main="RUVg", label=1:ncol(countsTFilt), col=c("orange", "darkseagreen3")[as.numeric(factor(grp))], gene.selection="common")
```


```{r}
# TMM
resTMM <- testEdgeR(countsTFilt, design, tmm=TRUE)
# Cqn
resCqn <- testEdgeR(countsTFilt, design, tmm=FALSE, offset=cqnObj$glm.offset)
#FQ
resFQ <- testEdgeR(fqcountsTFilt, design, tmm=FALSE)
# EDASEQ
resEDASeq <- testEdgeR(countsTFiltEDASeq, design, tmm=FALSE)
# GCQN
resGCQN <- testEdgeR(countsTFiltGCQN, design, tmm=FALSE)
# RUVg
resRUVg <- testEdgeR(ruvgcountsTFilt, design, tmm=FALSE)
# RUVs
resRUVs <- testEdgeR(ruvscountsTFilt, design, tmm=FALSE)

rafalib::mypar(mfrow=c(3,3))
hist(resTMM$table$PValue, main="TMM")
hist(resCqn$table$PValue, main="cqn")
hist(resFQ$table$PValue, main="FQ")
hist(resEDASeq$table$PValue, main="FQ-FQ")
hist(resGCQN$table$PValue, main="GC-QN")
hist(resRUVg$table$PValue, main="RUVg")
hist(resRUVs$table$PValue, main="RUVs")

table(cellT)

rm(peakSeqs, fqcountsTFilt, resCqn, resEDASeq, resFQ, resGCQN, resRUVg, resRUVs, resTMM, ruvRes, ruvsRes, wit, cqnObj, cpmCqn, cpmEDASeq, cpmFQ, cpmGCQN, cpmRUV, cpmTMM, cqncountsTFilt) ; gc()

```

# Adding signal

Here, we start with a set of T-cells from different cell types and create two groups.
Conditional on each T-cell type, we randomly assign the cells to one of two groups, attempting to balance the composition of cell types between the two groups.
Then, for each of the selected samples, we calculate

\[ \hat{f}_{ij} = y_{ij} / \sum_j y_{ij},  \]

i.e. the accessibility fraction for each sample $i$.
A random number of peaks will be simulated to be differentially accessible, with 50/50 up- and downregulation, by simulating fold changes from a log-normal distribution

\[ \beta_j \sim lN(0.8, 0.1),\]

which are multiplied with $\hat{f}_{ij}$.
A simulated sequencing depth $\tilde{N}_i$ is generated using

\[ \tilde{N}_i \sim U(N_{min}, N_{max}),  \]

with $N_{min}$ and $N_{max}$ the minumum and maximum library size in the dataset.

Given $\hat{f}_{ij}$ and $\tilde{N}_i$, we finally generate new accessibility counts using

\[ \tilde{Y}_{ij} | \hat{f}_{ij}, \tilde{N}_i \sim Mult(\tilde{N}_i, \hat{f}_{ij}).  \]




```{r, echo=FALSE}
evaluateSimulation <- function(simCounts, simGC, simWidth, design, deId, grSim, nSamples, grpSim){
  testEdgeR <- function(counts, design, tmm=FALSE, offset=NULL){
    d <- DGEList(counts)
    if(tmm) d <- calcNormFactors(d)
    if(!is.null(offset)) d$offset <- offset
    d <- estimateDisp(d, design)
    fit <- glmFit(d, design)
    lrt <- glmLRT(fit, coef=2)
    lrt$table$padj <- p.adjust(lrt$table$PValue, "fdr")
    return(lrt)
  }
  
  library(DESeq2)
  testDESeq2 <- function(counts, covarDf){
    dds <- DESeqDataSetFromMatrix(counts,
                                colData=covarDf,
                                design=as.formula("~ group"))
    dds <- DESeq(dds)
    res <- results(dds)
    return(res)
  }
  
  ## normalize
  ## TMM
  d <- DGEList(simCounts)
  d <- calcNormFactors(d)
  cpmTMM <- edgeR::cpm(d, normalized.lib.sizes=TRUE, log=TRUE, prior.count=0.25)
  
  ## FQN
  fqCounts <- FQnorm(simCounts)
  cpmFQ <- edgeR::cpm(fqCounts, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)
  
  ## qsmooth
  qsmoothObj <- qsmooth(object = simCounts, group_factor = grpSim)
  qsmoothCounts <- qsmoothData(qsmoothObj)
  
  ## cqn
  cqnObj <- cqn(simCounts, x=simGC, lengths=simWidth, sizeFactors=colSums(simCounts))
  cqnplot(cqnObj, xlab="GC content", lwd=2)
  cqnCounts <- 2^(cqnObj$y + cqnObj$offset)
  cpmCqn <- edgeR::cpm(cqnCounts, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)
  
  ## GCQN:
  gcGroups <- Hmisc::cut2(simGC, g=50)
  countsGCQN <- gcqn(simCounts, gcGroups, summary="median", round=TRUE)
  cpmGCQN <- edgeR::cpm(countsGCQN, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)
  
  ## smooth GCQN
  normCountsGcqnSmooth <- gcqn_qsmooth(simCounts, gcGroups, bio=grpSim)
  
  ## EDASeq
  library(EDASeq)
  wit <- withinLaneNormalization(x=as.matrix(simCounts), y=simGC, which="full")
  countsEDASeq <- betweenLaneNormalization(wit, "full")
  cpmEDASeq <- edgeR::cpm(countsEDASeq, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)
  
  ## RUVg
  library(RUVSeq)
  hk <- readRDS("~/data/genomes/hkListHumanGenomicRanges.rds")
  qh <- queryHits(findOverlaps(grSim[-deId], hk, type="within"))
  #qh <- queryHits(findOverlaps(grSim, hk, type="within"))
  negcon <- rownames(simCounts)[qh]
  ruvRes <- RUVg(as.matrix(simCounts), negcon, k=2)
  ruvgCounts <- ruvRes$normalizedCounts
  cpmRUV <- edgeR::cpm(ruvgCounts, normalized.lib.sizes=FALSE, log=TRUE, prior.count=0.25)
  
  
  # TMM
  resTMM <- testEdgeR(simCounts, design, tmm=TRUE)
  # DESeq2 MOR
  resDESeq2 <- testDESeq2(simCounts, covarDf=data.frame(group=grpSim))
  # Cqn
  resCqn <- testEdgeR(simCounts, design, tmm=FALSE, offset=cqnObj$glm.offset)
  #FQ
  resFQ <- testEdgeR(fqCounts, design, tmm=FALSE)
  # qsmooth
  resQsmooth <- testEdgeR(qsmoothCounts, design, tmm=FALSE)
  # EDASEQ
  resEDASeq <- testEdgeR(countsEDASeq, design, tmm=FALSE)
  # GCQN
  resGCQN <- testEdgeR(countsGCQN, design, tmm=FALSE)
  # smooth GCQN
  resGCQNSmooth <- testEdgeR(normCountsGcqnSmooth, design, tmm=FALSE)
  # RUVg
  resRUVg <- testEdgeR(ruvgCounts, design, tmm=FALSE)
  
  truth <- rep(0, nrow(simCounts))
  truth[deId] <- 1
  truthDf <- data.frame(truth=truth)
  rownames(truthDf) <- rownames(simCounts)
  
  library(iCOBRA)
  cbd <- COBRAData(pval = data.frame(TMM=resTMM$table$PValue,
                                     DESeq2=resDESeq2$pvalue,
                                     qsmooth=resQsmooth$table$PValue,
                                      cqn=resCqn$table$PValue,
                                      FQ=resFQ$table$PValue,
                                      edaseq=resEDASeq$table$PValue,
                                      gcqn=resGCQN$table$PValue,
                                      gcqn_smooth=resGCQNSmooth$table$PValue,
                                      RUVg=resRUVg$table$PValue,
                                      row.names=rownames(simCounts)),
            truth = truthDf)
  # cbd <- calculate_adjp(cbd)
  # cbd <- calculate_performance(cbd, binary_truth = "truth")
  # cbp <- prepare_data_for_plot(cbd)
  # p <- plot_fdrtprcurve(cbp, pointsize=2, yaxisrange=c(0,1),
  #                       title=paste0(nSamples," samples"))
  # print(p)
  # return(list(cbd=cbd, p=p))
  return(cbd)
}


simulateAndEvaluate <- function(seed, nTotal, inputCounts, grp, nDE, meanlog=0.8, sdlog=0.1, simGC, simWidth, grSim){
  
  set.seed(seed)
  n1 <- 1:(nTotal/2)
  n2 <- (nTotal/2+1):nTotal
  fractions <- sweep(inputCounts, 2, colSums(inputCounts), "/")
  inputCountssim <- matrix(NA, nrow=nrow(inputCounts), ncol=nTotal,
                     dimnames=list(rownames(inputCounts), paste0("sample", 1:nTotal)))
  remainingSamplesA <- which(grp == "A")
  remainingSamplesB <- which(grp == "B")
  
  deId <- sample(x=1:nrow(inputCounts), size=nDE)
  delta <- rep(0, nrow(inputCounts))
  sign <- rep(c(1,-1), each=nDE/2)
  if(length(sign) != nDE) sign <- c(sign,1)
  delta[deId] <- sign*log(rlnorm(n=nDE, meanlog=meanlog, sdlog=sdlog))
  hist(delta[deId],  breaks=40)
  
  # group 1
  for(ss in n1){
    sampleId <- sample(x=remainingSamplesA, size=1)
    remainingSamplesA <- remainingSamplesA[!remainingSamplesA %in% sampleId]
    curLS <- runif(n=1, min(colSums(inputCounts)), max(colSums(inputCounts)))
    curFracs <- fractions[,sampleId]
    curFracs[delta < 0] <- (curFracs[delta < 0]) * exp(abs(delta[delta < 0]))
    simY <- rmultinom(n=1, size=curLS, prob=curFracs)
    inputCountssim[,ss] <- simY
  }
  
  # group 2
  for(ss in n2){
    sampleId <- sample(x=remainingSamplesB, size=1)
    remainingSamplesB <- remainingSamplesB[!remainingSamplesB %in% sampleId]
    curLS <- runif(n=1, min(colSums(inputCounts)), max(colSums(inputCounts)))
    curFracs <- fractions[,sampleId]
    curFracs[delta > 0] <- (curFracs[delta > 0]) * exp(abs(delta[delta > 0]))
    simY <- rmultinom(n=1, size=curLS, prob=curFracs)
    inputCountssim[,ss] <- simY
  }
  
  plot(x=delta, y=log(rowMeans(inputCountssim[,n2]) / rowMeans(inputCountssim[,n1])))
  abline(0,1, col="red")
  abline(h=0, col="blue", lty=2)
  
  grpSim <- factor(rep(c("A", "B"), each=nTotal/2))
  evaluateSimulation(simCounts = inputCountssim, 
                     simGC = simGC, 
                     simWidth = simWidth, 
                     design = model.matrix(~grpSim), 
                     deId = deId, 
                     grSim = grSim,
                     nSamples = nTotal,
                     grpSim = grpSim)
}


```


## Iterate small effect sizes

```{r}
nDEParams <- round(nrow(countsTFilt)/c(10,4))
nTotalParams <- c(10, 20, 30, 40)
for(nde in 1:length(nDEParams)){
  for(ntot in 1:length(nTotalParams)){
      resList <- list()
    for(iter in 1:14){
      resList[[iter]] <- simulateAndEvaluate(seed=iter, 
                                             nTotal=nTotalParams[ntot], 
                                             inputCounts=countsTFilt, 
                                             grp=grp, 
                                             nDE=nDEParams[nde], 
                                             meanlog=0.8, 
                                             sdlog=0.1, 
                                             simGC=gcFilt, 
                                             simWidth=widthFilt, 
                                             grSim=gr[keep])
    }
    saveRDS(resList, file=paste0("simRes_n",nTotalParams[ntot],"_nDE",nde,".rds"))
  }
}


```



# Old code

```{r, eval=FALSE}
resList <- list()
pList <- list()
cbdList <- list()
pdf("iterate20Samples.pdf")
for(ss in 1:20){
 resList[[ss]] <- simulateAndEvaluate(seed=ss, nTotal=20, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])
 pList[[ss]] <- resList[[ss]]$p
 cbdList[[ss]] <- resList[[ss]]$cbd
}
dev.off()
pdf("iterate20samples_performance.pdf")
for(kk in seq(1,30,by=4)){
  print(cowplot::plot_grid(plotlist=pList[kk:(kk+3)]))
}
dev.off()
saveRDS(resList, file="resListCalderonSim.rds")
```

```{r, eval=FALSE}
resList20 <- readRDS("resListCalderonSim.rds")
cbdList20 <- lapply(resList20, function(x) x$cbd)
rm(resList20) ; gc()
# AUC of ROC curve





# sort acc to median value
ggplot(fdrDf, aes(x=method, y=FDR)) + 
  geom_boxplot() +
  geom_hline(yintercept=0.05, col="red")
rm(cbdList20) ; gc()
```

## Iterate small effect sizes, n=40

```{r, eval=FALSE}
resList <- list()
pList <- list()
cbdList <- list()
pdf("iterate40Samples.pdf")
for(ss in 1:20){
 resList[[ss]] <- simulateAndEvaluate(seed=ss, nTotal=40, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])
 pList[[ss]] <- resList[[ss]]$p
 cbdList[[ss]] <- resList[[ss]]$cbd
}
dev.off()
pdf("iterate40samples_performance.pdf")
for(kk in seq(1,20,by=4)){
  print(cowplot::plot_grid(plotlist=pList[kk:(kk+3)]))
}
dev.off()
saveRDS(resList, file="resListCalderonSim_40Samples.rds")
```

```{r, eval=FALSE}
resList40 <- readRDS("resListCalderonSim_40Samples.rds")
cbdList40 <- lapply(resList40, function(x) x$cbd)
rm(resList40) ; gc()
# AUC of ROC curve
getAUC <- function(cbd){
  aucVals <- roc(cbd) %>% dplyr::group_by(method) %>% 
    dplyr::mutate(FPR = c(0, FPR[-1])) %>%
    dplyr::mutate(dFPR = c(0, diff(FPR)),
                  dTPR = c(0, diff(TPR)),
                  TPRs = c(0, TPR[-length(TPR)])) %>%
    dplyr::mutate(AUC = cumsum(dFPR * dTPR/2 + dFPR * TPRs),
                  AUCflat = cumsum(dFPR * TPRs)) %>%
    summarize(maxAUC=max(AUC))
  return(aucVals)
}
getAUC_fdrtpr <- function(cbd){
  aucVals <- fdrtprcurve(cbd) %>% dplyr::group_by(method) %>% 
    dplyr::mutate(FDR = c(0, FDR[-1])) %>%
    dplyr::mutate(dFDR = c(0, diff(FDR)),
                  dTPR = c(0, diff(TPR)),
                  TPRs = c(0, TPR[-length(TPR)])) %>%
    dplyr::mutate(AUC = cumsum(dFDR * dTPR/2 + dFDR * TPRs),
                  AUCflat = cumsum(dFDR * TPRs)) %>%
    summarize(maxAUC=max(AUC))
  return(aucVals)
}
aucDf <- do.call(rbind,lapply(cbdList40, getAUC))
aucFDRDf <- do.call(rbind,lapply(cbdList40, getAUC_fdrtpr))
# sort acc to median value
ggplot(aucFDRDf, aes(x=method, y=maxAUC)) + 
  geom_boxplot()
ggplot(aucDf, aes(x=method, y=maxAUC)) + 
  geom_boxplot() 

# FDR control
getFDR <- function(cbd){
  fdrtpr(cbd) %>% 
    group_by(method) %>% 
    filter(thr == "thr0.05") %>% 
    select(method, FDR)
}
fdrDf <- do.call(rbind,lapply(cbdList40, getFDR))
# sort acc to median value
ggplot(fdrDf, aes(x=method, y=FDR)) + 
  geom_boxplot() +
  geom_hline(yintercept=0.05, col="red")
rm(cbdList40) ; gc()
```


## Small effect sizes

```{r, eval=FALSE}
simulateAndEvaluate(seed=10, nTotal=10, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=20, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=30, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=40, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=0.8, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])
```

## Moderate effect sizes

```{r, eval=FALSE}
simulateAndEvaluate(seed=10, nTotal=10, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=1.2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=20, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=1.2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=40, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=1.2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])
```

## High effect sizes

```{r, eval=FALSE}
simulateAndEvaluate(seed=10, nTotal=10, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=20, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])

simulateAndEvaluate(seed=10, nTotal=40, inputCounts=countsTFilt, grp=grp, nDE=1e4, meanlog=2, sdlog=0.1, simGC=gcFilt, simWidth=widthFilt, grSim=gr[keep])
```
